{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB-mYEzNp3-K",
        "outputId": "990fc49b-6911-46df-af22-17c4781e1a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLM-Utility-Cookbook'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 57 (delta 25), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (57/57), 1.07 MiB | 11.57 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Fuenfgeld/LLM-Utility-Cookbook.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install Required Libraries**\n",
        "\n",
        "In this section, we install the required libraries for OCR. We use Tesseract for OCR and Poppler-utils for converting PDFs to images."
      ],
      "metadata": {
        "id": "5U_TCZSRqHUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt-get install -y poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwXH9LWGqDB-",
        "outputId": "6ed683e1-eff8-44f3-b26b-8bd87ed653f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 0s (12.0 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 120875 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.2 [186 kB]\n",
            "Fetched 186 kB in 0s (1,045 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 120922 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.2) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!pip install pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkm-WTx6qMrd",
        "outputId": "6a60d088-93b9-47c9-f118-56337fa83c20"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.16.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "gcVUB_nwqSEd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagePath ='/content/LLM-Utility-Cookbook/data/DocImage.png'"
      ],
      "metadata": {
        "id": "ws3XXbi0qUpa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extractedText = pytesseract.image_to_string(Image.open(imagePath))"
      ],
      "metadata": {
        "id": "YRyAKgUXqabW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extractedText"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "HdArBVD5qciH",
        "outputId": "d194bb8f-a519-40e7-8ad5-5a44d55be9bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"LLM-Utility-Cookbook\\n\\n \\n\\nHello, future LLM enthusiasts! Welcome to the LLM-Utility-Cookbook, a place where we'll explore, understand, and\\nplay with a myriad of tools and techniques related to Large Language Models (LLMs). This repository serves as an\\nextension of our lectures, bridging theory and practice in the most interactive way possible.\\n\\nOur Learning Menu ™\\n\\n \\n\\nHere's what we'll be exploring together:\\n\\n. Voice to Text: We'll unravel the magic behind turning spoken words into written text.\\n\\n. Text to Voice: A dive into how we can transform static text into expressive audible speech.\\n. Document Scan to Text: Learn how to breathe digital life into your physical documents.\\n\\n. Prompts: Together, we'll optimize and manage prompts to extract the most from our LLMs.\\nMemory: Get hands-on with persisting states between calls in a chain or agent.\\n\\n. Indexes: We'll tinker with loading, querying, and updating external data.\\n\\nChains: Discover the art of crafting structured sequences of calls to LLMs or other utilities.\\n. Agents: Learn to create agents that decide, act, and learn until a task is complete.\\n\\nOMAN OAR WD AB\\n\\n. Callbacks: Dive into the world of debugging and introspection with callbacks.\\n\\nGetting Started ¥\\n\\n \\n\\nTo join the learning journey, clone this repository or use the google colab links and roll up your sleeves for some\\ncoding action.\\n\\nYour Contributions ®\\n\\n \\n\\nLearning is a two-way street, and your inputs are highly valued!\\n\\nLicense =\\n\\n \\n\\nThis educational content is shared under the MIT License.\\n\\x0c\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PDF to Image to Text**\n",
        "For PDFs, the process is a bit different. Since OCR engines typically work on images, we first convert the PDF to images. Each page of the PDF is converted into a separate image. Then, we apply the OCR engine to each image to extract the text."
      ],
      "metadata": {
        "id": "rQDtZu8HqhVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "import os"
      ],
      "metadata": {
        "id": "NgZ7HzSyqeBZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert PDF to Images**\n",
        "We convert each page of the PDF into a separate image using the pdf2image library. These images are saved in a specified output directory.\n",
        "\n"
      ],
      "metadata": {
        "id": "UeMehaUbqnwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdfPath = '/content/LLM-Utility-Cookbook/data/ScanPDF.pdf'\n",
        "outputDirPath = '/content/pdfImages'\n",
        "os.makedirs(outputDirPath,exist_ok=True)\n",
        "\n",
        "images = convert_from_path(pdfPath)\n",
        "for i, image in enumerate(images):\n",
        "  image.save(outputDirPath + '/output' + str(i) + '.jpg', 'JPEG')"
      ],
      "metadata": {
        "id": "1v9cZxlxqlWp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extract Text from Images**\n",
        "We iterate through each image that resulted from the PDF conversion and extract text using Tesseract. The text is saved in a dictionary with the image's filename as the key for easy lookup."
      ],
      "metadata": {
        "id": "nq4LMFfcqvvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagesToProcess = os.listdir(outputDirPath)\n",
        "extractedTextPages = {}\n",
        "\n",
        "for tempFileName in imagesToProcess:\n",
        "  tempPath = outputDirPath + '/' + tempFileName\n",
        "  extractedTextPages[tempFileName] = pytesseract.image_to_string(Image.open(tempPath))"
      ],
      "metadata": {
        "id": "_r2ws2g5qsJY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extractedTextPages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrcFUk0Nqzpe",
        "outputId": "85c8e42e-f630-41e4-a107-f890370e97da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'output0.jpg': \" \\n\\nLLM-Utility-Cookbook\\n\\nHello, future LLM enthusiasts! Welcome to the LLM-Utility-Cookbook, a place where\\nwe'll explore, understand, and play with a myriad of tools and techniques related to\\nLarge Language Models (LLMs). This repository serves as an extension of our\\nlectures, bridging theory and practice in the most interactive way possible.\\n\\nOur Learning Menu &\\nHere's what we'll be exploring together:\\n\\n1. Voice to Text: We'll unravel the magic behind turning spoken words into\\nwritten text.\\n\\n2. Text to Voice: A dive into how we can transform static text into expressive\\naudible speech.\\n\\n3. Document Scan to Text: Learn how to breathe digital life into your physical\\ndocuments.\\n\\n4. Prompts: Together, we'll optimize and manage prompts to extract the most\\nfrom our LLMs.\\n\\n5. Memory: Get hands-on with persisting states between calls in a chain or\\nagent.\\n\\n6. Indexes: We'll tinker with loading, querying, and updating external data.\\n\\n7. Chains: Discover the art of crafting structured sequences of calls to LLMs or\\nother utilities.\\n\\n8. Agents: Learn to create agents that decide, act, and learn until a task is\\ncomplete.\\n\\n9. Callbacks: Dive into the world of debugging and introspection with callbacks.\\n\\nGetting Started 7\\n\\nTo join the learning journey, clone this repository or use the google colab links and\\nroll up your sleeves for some coding action.\\n\\nYour Contributions ..\\n\\nLearning is a two-way street, and your inputs are highly valued!\\n\\nLicense &\\n\\nThis educational content is shared under the MIT License.\\n\\ned aT oad Seppe Se Await iaA-tea fod b\\nparts Stns fl re etiam iS 653 ix\\n\\n~~\\n\\n \\n\\x0c\"}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AWxI4tK7q1py"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}